"""PASCAL VOC2007"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/51_pascal.ipynb.

# %% auto 0
__all__ = ['VOC_CLASSES', 'xmean', 'xstd', 'show_voc_sample', 'get_class_distribution', 'get_image_sizes', 'show_class_examples',
           'calculate_dataset_stats', 'get_stats_dataloader', 'create_voc_datasets', 'voc_extract', 'onehot_tfm',
           'denorm', 'get_classification_model', 'show_image_batch']

# %% ../nbs/51_pascal.ipynb 3
from minai import *

import torch
import torch.nn as nn
from torch import tensor
from torch.utils.data import DataLoader
import torch.nn.functional as F

import torchvision.transforms.v2.functional as TF
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torchvision.transforms import v2

from torcheval.metrics import MulticlassAccuracy

import fastcore.all as fc
from fastcore.utils import L
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd

from datasets import load_dataset, load_dataset_builder

from IPython.display import display, Image

from .core import *
from .darknet import *

# %% ../nbs/51_pascal.ipynb 8
VOC_CLASSES = L(['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 
               'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person',
               'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'])

# %% ../nbs/51_pascal.ipynb 14
def show_voc_sample(ds, idx, figsize=(12,10)):
    img, target = ds[idx]
    objects = target['annotation']['object']
    img_array = np.array(img)
    fig, ax = plt.subplots(figsize=figsize)
    ax.imshow(img_array)
    width = int(target['annotation']['size']['width'])
    height = int(target['annotation']['size']['height'])
    for obj in objects:
        bbox = obj['bndbox']
        xmin = int(bbox['xmin'])
        ymin = int(bbox['ymin'])
        xmax = int(bbox['xmax'])
        ymax = int(bbox['ymax'])
        rect = plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, 
                            fill=False, edgecolor='red', linewidth=2)
        ax.add_patch(rect)
        ax.text(xmin, ymin-5, obj['name'], 
                bbox=dict(facecolor='red', alpha=0.5), fontsize=12, color='white')
    ax.set_title(f"Image {idx}: {', '.join([obj['name'] for obj in objects])}")
    ax.axis('off')
    plt.tight_layout()
    plt.show()
    print(f"Image size: {width}x{height}")
    print(f"Number of objects: {len(objects)}")
    for i, obj in enumerate(objects):
        print(f"Object {i+1}: {obj['name']}, Difficult: {obj['difficult']}, Truncated: {obj['truncated']}")

# %% ../nbs/51_pascal.ipynb 16
def get_class_distribution(ds):
    "Get distribution of classes in the dataset"
    counts = {}
    for i in range(len(ds)):
        img, target = ds[i]
        for obj in target['annotation']['object']:
            cls = obj['name']
            counts[cls] = counts.get(cls, 0) + 1
    return pd.Series(counts).sort_values(ascending=False)

# %% ../nbs/51_pascal.ipynb 18
def get_image_sizes(ds, n=100):
    "Get distribution of image sizes in the dataset"
    sizes = []
    for i in range(min(n, len(ds))):
        img, _ = ds[i]
        sizes.append(img.size)
    return pd.DataFrame(sizes, columns=['width', 'height'])

# %% ../nbs/51_pascal.ipynb 20
def show_class_examples(ds, class_name, n=4):
    "Show examples of a specific class"
    examples = []
    for i in range(len(ds)):
        img, target = ds[i]
        if any(obj['name'] == class_name for obj in target['annotation']['object']):
            examples.append((img, target))
            if len(examples) >= n: break
    
    fig, axes = subplots(1, n, figsize=(n*4, 4))
    for i, (img, target) in enumerate(examples):
        axes[i].imshow(img)
        axes[i].set_title(f"Example {i+1}")
        axes[i].axis('off')
        
        for obj in target['annotation']['object']:
            if obj['name'] == class_name:
                bbox = obj['bndbox']
                x1, y1 = int(bbox['xmin']), int(bbox['ymin'])
                x2, y2 = int(bbox['xmax']), int(bbox['ymax'])
                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, 
                                   fill=False, edgecolor='green', linewidth=2)
                axes[i].add_patch(rect)
    
    plt.suptitle(f"Examples of '{class_name}'")
    plt.tight_layout()
    return fig

# %% ../nbs/51_pascal.ipynb 23
def calculate_dataset_stats(dataloader, max_images=None):
    """Calculate mean and std of a dataset using a dataloader.
    
    Args:
        dataloader: DataLoader instance
        max_images: Maximum number of images to use (None = use all)
    
    Returns:
        mean and std per channel
    """
    # Create running sums
    channel_sum = torch.zeros(3)
    channel_sum_squared = torch.zeros(3)
    num_pixels = 0
    
    # Use tqdm for progress bar
    from tqdm.auto import tqdm
    
    for i, (images, _) in enumerate(tqdm(dataloader)):
        if max_images is not None and i*dataloader.batch_size >= max_images:
            break
        
        # Make sure images are in the right format
        if not isinstance(images, torch.Tensor):
            continue
            
        # Reshape: [B, C, H, W] -> [B, C, H*W]
        b, c, h, w = images.shape
        images = images.reshape(b, c, -1)
        
        # Update sums
        channel_sum += images.sum(dim=[0, 2])
        channel_sum_squared += (images**2).sum(dim=[0, 2])
        num_pixels += b * h * w
    
    # Calculate mean and std
    mean = channel_sum / num_pixels
    std = torch.sqrt((channel_sum_squared / num_pixels) - (mean**2))
    
    return mean, std

# %% ../nbs/51_pascal.ipynb 24
def get_stats_dataloader(data_path, bs=32, year='2007'):
    """Create a dataloader for calculating dataset statistics"""
    # Basic transforms without normalization
    basic_tfms = v2.Compose([
        v2.Resize(256),
        v2.CenterCrop(224),
        v2.ToImage(),
        v2.ToDtype(torch.float32, scale=True)  # Scales to [0, 1]
    ])
    
    # Create dataset with basic transforms
    ds = datasets.VOCDetection(
        root=data_path, 
        year=year, 
        image_set='train', 
        download=False,
        transform=basic_tfms
    )
    
    # Create a dataloader with a simple collate function that only returns images
    def simple_collate(batch): return torch.stack([item[0] for item in batch]), None
    
    return DataLoader(ds, batch_size=bs, shuffle=False, 
                     collate_fn=simple_collate, num_workers=4)

# %% ../nbs/51_pascal.ipynb 28
from torch.utils.data import default_collate
from operator import attrgetter, itemgetter

# %% ../nbs/51_pascal.ipynb 30
def create_voc_datasets(data_path, train_tfms=None, valid_tfms=None, year='2007'):
    "Create training and validation datasets for VOC"
    if train_tfms is None:
        train_tfms = v2.Compose([
            v2.RandomResizedCrop(224),
            v2.RandomHorizontalFlip(),
            v2.ToImage(),
            v2.ToDtype(torch.float32, scale=True),
            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    if valid_tfms is None:
        valid_tfms = v2.Compose([
            v2.Resize(256),
            v2.CenterCrop(224),
            v2.ToImage(),
            v2.ToDtype(torch.float32, scale=True),
            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    train_ds = datasets.VOCDetection(root=data_path, year=year, image_set='train', download=False,
                                    transform=train_tfms)
    valid_ds = datasets.VOCDetection(root=data_path, year=year, image_set='val', download=False,
                                   transform=valid_tfms)
    return train_ds, valid_ds

# %% ../nbs/51_pascal.ipynb 35
def voc_extract(field='name'):
    """Create a function that extracts a specific field from VOC annotations"""
    def _extract(targ):
        return L(fc.nested_attr(targ, 'annotation.object')).itemgot(field)
    return _extract

# %% ../nbs/51_pascal.ipynb 46
def onehot_tfm(targ, clss=VOC_CLASSES):
    get = voc_extract(field='name')
    names = get(targ)
    one_hot = torch.zeros(len(clss))
    idxs = tensor([clss.index(n) for n in names])
    one_hot.scatter_(0, idxs, 1)
    return one_hot

# %% ../nbs/51_pascal.ipynb 52
def _rvs_onehot_tfm(onehot): return VOC_CLASSES[np.where(onehot == 1)[0]]

# %% ../nbs/51_pascal.ipynb 61
xmean,xstd = (tensor([0.485, 0.456, 0.406]), tensor([0.229, 0.224, 0.225]))

# %% ../nbs/51_pascal.ipynb 62
def denorm(x): return (x*xstd[:,None,None]+xmean[:,None,None]).clip(0,1)

# %% ../nbs/51_pascal.ipynb 64
def get_classification_model(num_classes=len(VOC_CLASSES)):
    "Create a multi-label classification model based on darknet19"
    backbone = get_darknet19()
    model = nn.Sequential(
        backbone,
        nn.AdaptiveAvgPool2d(1),
        nn.Flatten(),
        nn.Linear(1024, 512),
        nn.ReLU(inplace=True),
        nn.Dropout(0.5),
        nn.Linear(512, num_classes)
    )
    return model

# %% ../nbs/51_pascal.ipynb 67
@fc.patch
@fc.delegates(show_images)
def show_image_batch(self:Learner, max_n=9, cbs=None, tfm_x=None, tfm_y=None, **kwargs):
    self.fit(1, cbs=[SingleBatchCB()]+fc.L(cbs))
    xb,yb = to_cpu(self.batch)
    feat = fc.nested_attr(self.dls, 'train.dataset.features')
    if feat is None: titles = np.array(to_cpu(yb))     # when fitting, yb is in GPU
    else:
        names = feat['label'].names
        titles = [names[i] for i in yb]
    xb = tfm_x(xb[:max_n]) if tfm_x else xb[:max_n]
    titles = tfm_y(titles[:max_n]) if tfm_y else titles[:max_n]
    show_images(xb, titles=titles, **kwargs)

# %% ../nbs/51_pascal.ipynb 80
from torcheval.metrics import TopKMultilabelAccuracy
from torcheval.metrics import MultilabelAccuracy
from torcheval.metrics import MultilabelAUPRC
